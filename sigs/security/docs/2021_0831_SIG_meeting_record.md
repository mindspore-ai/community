# 主题：《联邦学习任务中的数据安全和隐私保护》

## 时间：2021.8.31

此次会议，Richard Wang、Mike Jin、郭含熙以及Seng Tang给大家带来了以下精彩的分享，感谢他们！参会的宋涛老师、陈晋音老师、金鑫老师和李晓东老师也给大家解决了很多疑问，非常感谢他们！！

topic １，《MindArmour技术架构概览》：Richard Wang作为MindArmour技术架构师，向大家介绍了未来AI计算框架面临的挑战和趋势，以及MindSpore的安全可信目标。AI模型的稳健性、可解释性以及隐私保护都是我们正在探索的方向。

topic ２，《MindSpore Federated中的数据安全和隐私保护策略》：MindArmour团队成员Mike Jin通过简单易懂的例子给大家介绍了什么是联邦学习、联邦学习场景中的隐私泄露风险以及MindSpore联邦学习框架的隐私保护策略，引发了大家的热烈提问。

topic ３，《一种新型的联邦学习防御方法》：上海交大的郭含熙同学给大家分享了自己近期在顶会“The ACM Symposium on Cloud Computing 2021”上面发表的一篇论文，提出了一种客户端和中心服务器端联合抵御拜占庭攻击的防御方法。在大家讨论提问的过程中，引出了一个很好的问题：如何在保护数据安全和隐私的情况下，依然有效地进行恶意客户端的检测？

topic ４，《本地差分隐私技术概览及应用》：MindArmour团队成员Seng Tang同学给大家详细介绍了MindSpore Federated中使用的本地差分隐私技术。从问卷调查案例、随机响应案例到再到拉普拉斯机制，大家明白了为什么要使用差分隐私以及差分隐私的基本定义。

## 提问和回答

### Part 1 (after topic 2)

Q: 联邦学习架构图中的ELB是什么？有什么用？

A: ELB是一个中间件，负责把海量的client请求随机路由到各server节点；

Q: MindSpore联邦学习的安全聚合有没有涉及密码学的知识？

A: 有的。我们的实现是成对加掩码的加密方式，这是一种安全多方计算协议，底层用到了很多密码学的知识，包括密钥协商、传统加解密、签名验签等等。

Q: 图像重构攻击是为了重构一个训练数据吗？我们目前是实现了垂直联邦场景还是横向联邦场景？

A: 是的，重构数据包含图像数据或文字数据，我们目前只做了横向联邦场景。

Q: 后续继续做下去的点包括什么，是偏向于应用的边缘端场景，还是说把最新的攻防算法在MindSpore上进行集成？

A: 这两个方向我们都有计划，一方面希望基于真实场景进行攻击测试来侧面验证差分隐私的有效性；另一方面我们也会持续关注新的算法。

Q: 这次开源MindSpore联邦学习框架有没有开源一些数据集？或者能否分享一些实验数据集？

A: 没有，但是后续可以通过高校合作的方式分享数据（**看来大家对数据集的需求挺强烈的**）。

Q: 目前比较多的场景是横向联邦，有没有考虑往垂直联邦场景做？

A: 目前我们做横向联邦是因为公司的业务需求，垂直联邦也在计划做。

Q: 联邦学习一些思想和安全多方计算类似，请问一下这两个领域有什么区别和联系？

A: 可以从几个维度来看。从安全性来看，安全多方计算可以提供严格的安全保障，而传统的联邦学习以明文的方式上传数据还是会泄露隐私；从通信方式来看，安全多方计算是p2p的方式，每一个参与方的地位是对等的，而联邦学习中的客户端和中心服务器的地位是不对等的；从计算效率来看，安全多方计算比联邦学习低很多。

Q: 假如我在MindSpore上做实验模拟，能不能不考虑这些通信的底层呢？

A: 这些是不需要的，开发者只需要关心上层聚合算法的实现。

Q: MindSpore联邦学习有大规模地部署到实际场景中吗？

A: 有的，MindSpore Federated的端侧代码可以部署在安卓环境上，就是为了在真实场景中部署。

Q: 请问下次能详细介绍一下安全聚合算法吗？这一块资料很少。

A: 可以的，非常欢迎下次参加！

Q: 如何衡量隐私保护的效果？有没有衡量指标？或者通过可视化让用户易于理解？

A: 很好的问题，这也是我们一直在思考的问题。目前我们认为一方面可以通过差分隐私预算$\epsilon$和$\delta$来度量隐私保护能力；另一方面可以通过攻击方法来侧面反映隐私保护能力。

### Part 2 (after topic 3 and 4)

Q: 对于《一种新型的联邦学习防御方法》，如何检测攻击者？有多少客户端发出预警才会触发检测？

A: 中心服务器是根据客户端的预警信息去进行检测判断的；一旦有攻击者导致全局模型恶化，就会有部分客户端发出预警，只要有一个客户端发出预警，中心服务器就会进行检查。

Q: 检测算法需要拿到模型的明文形式，与前面一个主题的隐私保护方案不匹配，如何同时做到隐私保护和对恶意客户端的检测？

A: 这是个很好的问题，值得我们继续探索！

Q: 发生攻击后，端侧和云侧会回退到之前的模型继续进行训练吗？

A: 是的。

Q: 您讲的防御算法需要端侧和云侧协同运作，如果端侧发出的预警信息被篡改了，防御策略还是否有效？

A: 有效。如果有客户端发生假预警，会触发云侧的惩罚机制，将恶意客户端或者假报警客户端罚出训练流程；如果应该报警的客户端没有报警，那么总会有正常的客户端发出报警。

Q: MindSpore Federated的差分隐私用的是什么算法？

A: 使用的是本地高斯差分隐私算法，算法会根据用户设置的 $\epsilon$ 、 $\delta$和norm_clip_bound计算出$\sigma$，然后使用高斯分布$N(0, \sigma^2)$产生和模型参数同等维度的噪声矩阵，并附加在原模型参数上。

Q: 本地差分隐私和集中式的差分隐私的区别是什么？

A: 中心式的差分隐私是指聚合之后对整个模型加一次噪声，这种方案属于DP(Differential privacy)范畴。这种场景下的中心服务器是可信的，用户把真实的梯度上传到服务方，然后中心服务器聚合之后加噪，用户无法通过服务器下发的聚合模型推测哪些用户参与了本次训练。而本地化的差分隐私具有更高的隐私保护性能，目的是使得中心服务器也不能区分参与用户的真实信息。

Q: 有没有做端测数据标签质量的评估工作？

A: 目前有使用影响函数检测的方式，期待其他同学分享更多的方法！

## 资料获取

如果有小伙伴想看我们会议的回放，可以在哔哩哔哩搜索账号“MindSpore官方”，我们的录屏已经上传至MindSpore官方账号！点击[链接](https://www.bilibili.com/video/BV14g411V7nZ?spm_id_from=333.999.0.0)即可直接到达。

## 未来方向展望

１，垂直联邦、迁移学习场景下的隐私保护策略；

２，如何在实现数据安全和隐私保护的前提下，还能对恶意客户端进行检测防御？

３，如何有效地评估端侧数据的标签质量？

４，不仅仅是隐私保护，还需要考虑后门攻击、投毒攻击等威胁。

最后，感谢这次SIG的所有参与者！如果您还有什么疑问，或者还有想了解的课题，欢迎私信我们的公众号！
另外，我们也非常欢迎伙伴们主动报名，在下一次SIG上分享自己的成果，和大家共同进步！（会有精美礼品赠送哦！）
下期再见！！

PS：这期获得获奖同学有：Mr. Yang，胡先生，irrational，tanjuntao，hanxi Guo，恭喜他们！！
礼品会在下周一寄出，记得查收～
